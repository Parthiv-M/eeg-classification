{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05656b6c",
   "metadata": {},
   "source": [
    "# Neural Network \n",
    "\n",
    "This notebook contains the neural network we built for classification of subjects based on EEG signals taken from the Keirn and Aunon dataset. The preprocessing and feature extraction using Burg's AR coefficients is explained in [this notebook](https://github.com/Parthiv-M/eeg-classification/blob/main/EEG%20Preprocessing%20and%20Feature%20Extraction.ipynb). The extracted features were then given as inputs to this neural network. We have tried to implement the neural network to closely resemble the original implementation as given in [this paper](https://www.cs.colostate.edu/~anderson/wp/pubs/anderson-sijercic-96.pdf). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa87fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94dd18fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_label_columns(sub_df):\n",
    "    sub_df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "    mod_df = sub_df.loc[:, ~sub_df.columns.isin(['subject', 'trial'])]\n",
    "    return mod_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be09dc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relace_task_with_num(sub_df):\n",
    "    tasks = {\n",
    "        'baseline' : 0,\n",
    "        'letter-composing' : 1,\n",
    "        'multiplication' : 2,\n",
    "        'counting' : 3,\n",
    "        'rotation' : 4\n",
    "    }\n",
    "    sub_df = pd.DataFrame(np.array(sub_df))\n",
    "    for idx, task in enumerate(sub_df[0]):\n",
    "        sub_df.at[idx, 0] = tasks[task]\n",
    "    return sub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfe5e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_train_data(sub_df):\n",
    "    X_train = sub_df.iloc[:,1:7]\n",
    "    print(\"X_train shape: \", X_train.shape)\n",
    "    Y_train = sub_df.iloc[:,:-6]\n",
    "    print(\"Y_train shape: \", Y_train.shape)\n",
    "    X_train = np.array(X_train)\n",
    "    X_train = X_train.astype(np.float)\n",
    "    Y_train = np.array(Y_train)\n",
    "    Y_train_cat = tf.keras.utils.to_categorical(Y_train, num_classes=5)\n",
    "    Y_train_cat = Y_train_cat.astype(np.float)\n",
    "    print(\"Y_train_cat shape: \", Y_train_cat.shape)\n",
    "    return X_train, Y_train_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0cceef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_val_data(val_df):\n",
    "    X_val = val_df.iloc[:,1:7]\n",
    "    print(\"X_val shape: \", X_val.shape)\n",
    "    Y_val = val_df.iloc[:,:-6]\n",
    "    print(\"Y_val shape: \", Y_val.shape)\n",
    "    X_val = np.array(X_val)\n",
    "    X_val = X_val.astype(np.float)\n",
    "    Y_val = np.array(Y_val)\n",
    "    Y_val_cat = tf.keras.utils.to_categorical(Y_val, num_classes=5)\n",
    "    Y_val_cat = Y_val_cat.astype(np.float)\n",
    "    print(\"Y_val_cat shape: \", Y_val_cat.shape)\n",
    "    return X_val, Y_val_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e75fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_test_data(test_df):\n",
    "    X_test = test_df.iloc[:,1:7]\n",
    "    print(\"X_test shape: \", X_test.shape)\n",
    "    Y_test = test_df.iloc[:,:-6]\n",
    "    print(\"Y_test shape: \", Y_test.shape)\n",
    "    X_test = np.array(X_test)\n",
    "    X_test = X_test.astype(np.float)\n",
    "    Y_test = np.array(Y_test)\n",
    "    Y_test_cat = tf.keras.utils.to_categorical(Y_test, num_classes=5)\n",
    "    Y_test_cat = Y_test_cat.astype(np.float)\n",
    "    print(\"Y_test_cat shape: \", Y_test_cat.shape)\n",
    "    return X_test, Y_test_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacf0bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_neural_network():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, activation='relu', input_dim=6))\n",
    "    model.add(Dense(5, activation='softmax'))\n",
    "    sgd = SGD(lr=0.1, decay=0.01, momentum=0.9, nesterov=True)\n",
    "    return model, sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a34db7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_nn_model(model, sgd):\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc899124",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, X_train, Y_train, X_val, Y_val, epochs=3000, batch_size=128):\n",
    "    model.fit(X_train,Y_train,epochs=epochs,batch_size=batch_size,validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfade34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, Y_test, batch_size=128):\n",
    "    score = model.evaluate(X_test,Y_test,batch_size=batch_size)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c2f699",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_subject_wise(coeff_df):\n",
    "    sub_list = ['subject 1', 'subject 3', 'subject 5', 'subject 6']\n",
    "    train_df_list = []\n",
    "    test_df_list = []\n",
    "    val_df_list = []\n",
    "    score_list = []\n",
    "    for subject in sub_list:\n",
    "        sub_df_train = coeff_df[(coeff_df['subject'] == subject) & (coeff_df['trial'] <= 8)]\n",
    "        sub_df_val = coeff_df[(coeff_df['subject'] == subject) & (coeff_df['trial'] == 9)]\n",
    "        sub_df_test = coeff_df[(coeff_df['subject'] == subject) & (coeff_df['trial'] == 10)]\n",
    "        \n",
    "        mod_sub_df_train = remove_label_columns(sub_df_train)\n",
    "        mod_sub_df_val = remove_label_columns(sub_df_val)\n",
    "        mod_sub_df_test = remove_label_columns(sub_df_test)\n",
    "        \n",
    "        train_df_list.append(mod_sub_df_train)\n",
    "        test_df_list.append(mod_sub_df_test)\n",
    "        val_df_list.append(mod_sub_df_val)\n",
    "        \n",
    "        mod_sub_df_train = relace_task_with_num(mod_sub_df_train)\n",
    "        mod_sub_df_val = relace_task_with_num(mod_sub_df_val)\n",
    "        mod_sub_df_test = relace_task_with_num(mod_sub_df_test)\n",
    "        \n",
    "        X_train, Y_train = gen_train_data(mod_sub_df_train)\n",
    "        X_val, Y_val = gen_val_data(mod_sub_df_val)\n",
    "        X_test, Y_test = gen_test_data(mod_sub_df_test)\n",
    "        \n",
    "        model, sgd = build_neural_network()\n",
    "        build_nn_model(model, sgd)\n",
    "        \n",
    "        start = datetime.datetime.now()\n",
    "        train_model(model, X_train, Y_train, X_val, Y_val)\n",
    "        end = datetime.datetime.now()\n",
    "        time_diff = end - start\n",
    "        print(\"\\nTime taken for training: \", time_diff.total_seconds(), \" seconds\")\n",
    "        \n",
    "        start = datetime.datetime.now()\n",
    "        score = evaluate_model(model, X_test, Y_test, batch_size=64)\n",
    "        end = datetime.datetime.now()\n",
    "        time_diff = end - start\n",
    "        print(\"\\nTime taken for evaluating: \", time_diff.total_seconds(), \" seconds\")\n",
    "        \n",
    "        print(\"\\n\\nScore for \", subject, \" is \", score)\n",
    "        \n",
    "        score_list.append(score)\n",
    "        \n",
    "        print(subject + \" done\")\n",
    "        print(\"=============================\")\n",
    "    return score_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b16502",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    coeff_df = pd.read_csv('coefficients_1.csv')\n",
    "    \n",
    "    score_list = run_subject_wise(coeff_df)\n",
    "\n",
    "    accuracies = []\n",
    "    for score in score_list:\n",
    "        accuracies.append(score[1])\n",
    "    \n",
    "    plt.plot(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b3d285",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
